{
  "hash": "7fcea9c948b532bbe7d3387f70c535d6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"In Class Exercise 07\"\nauthor: \"Qu JunJie\"\ndate: \"16 October 2024\"\ndate-modified: \"last-modified\"\nexecute: \n  eval: true\n  echo: true\n  message: false\n  freeze: true\n  warning: false\n---\n\n\n# 1. Getting Started\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(olsrr, ggstatsplot, ggpubr, \n               sf, spdep, GWmodel, tmap,\n               tidyverse, gtsummary, performance,\n               see, sfdep)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\npackage 'glue' successfully unpacked and MD5 sums checked\npackage 'rlang' successfully unpacked and MD5 sums checked\npackage 'ggstatsplot' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n\tC:\\Users\\cttdn\\AppData\\Local\\Temp\\RtmpiG1xtG\\downloaded_packages\npackage 'cli' successfully unpacked and MD5 sums checked\npackage 'glue' successfully unpacked and MD5 sums checked\npackage 'gtsummary' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n\tC:\\Users\\cttdn\\AppData\\Local\\Temp\\RtmpiG1xtG\\downloaded_packages\n```\n\n\n:::\n:::\n\n\n# 2. Import data\n\n## 2.1 **URA Master Plan 2014 planning subzone boundary**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncondo_resale <- read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# mpsz <- read_rds(\"data/geospatial/mpsz.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# condo_resale_sf <- read_rds(\n#   \"data/rds/condo_resale_sf.rds\")\n```\n:::\n\n\n# 3. Correlation Analysis - ggstatsplot methods\n\nInstead of using corrplot package, in the code chunk below, [`ggcorrmat()`](https://indrajeetpatil.github.io/ggstatsplot/reference/ggcorrmat.html) of [**ggstatsplot**](https://indrajeetpatil.github.io/ggstatsplot/index.html) is used.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ggcorrmat(condo_resale[, 5:23])\n```\n:::\n\n\n# 4.Buildi**ng a Hedonic Pricing Model by using Multiple Linear Regression Method**\n\nThe code chunk below using `lm()` to calibrate the multiple linear regression model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# condo_mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + \n#                   AGE   + PROX_CBD + PROX_CHILDCARE + \n#                   PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n#                   PROX_HAWKER_MARKET    + PROX_KINDERGARTEN + \n#                   PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n#                   PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + \n#                   PROX_SUPERMARKET + PROX_BUS_STOP + \n#                   NO_Of_UNITS + FAMILY_FRIENDLY + \n#                   FREEHOLD + LEASEHOLD_99YR, \n#                 data=condo_resale_sf)\n# summary(condo_mlr)\n```\n:::\n\n\n# 5. Model Assessment: olsrr method\n\nIn this section, we would like to introduce you a fantastic R package specially programmed for performing OLS regression. It is called [**olsrr**](https://olsrr.rsquaredacademy.com/). It provides a collection of very useful methods for building better multiple linear regression models:\n\n-   comprehensive regression output\n\n-   residual diagnostics\n\n-   measures of influence\n\n-   heteroskedasticity tests\n\n-   model fit assessment\n\n-   variable contribution assessment\n\n-   variable selection procedures\n\n## 5.1 Generating tidy linear regression report\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ols_regress(condo_mlr)\n```\n:::\n\n\n#### **Multicolinearuty**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ols_vif_tol(condo_mlr)\n```\n:::\n\n\n#### **Variable selection**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# condo_fw_mlr <- ols_step_forward_p(\n#   condo_mlr,\n#   p_val = 0.05,\n#   details = FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# plot(condo_fw_mlr)\n```\n:::\n\n\n## 5.2 Visualising model parameters\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ggcoefstats(condo_mlr,\n#             sort = \"ascending\")\n```\n:::\n\n\n### Test for Non-Linearity\n\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\n\nIn the code chunk below, the [`ols_plot_resid_fit()`](https://olsrr.rsquaredacademy.com/reference/ols_plot_resid_fit.html) of **olsrr** package is used to perform linearity assumption test.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ols_plot_resid_fit(condo_fw_mlr$model)\n```\n:::\n\n\nThe figure above reveals that most of the data poitns are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n## 5.3 **Test for Normality Assumption**\n\nLastly, the code chunk below uses [`ols_plot_resid_hist()`](https://olsrr.rsquaredacademy.com/reference/ols_plot_resid_hist.html) of *olsrr* package to perform normality assumption test.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ols_plot_resid_hist(condo_fw_mlr$model)\n```\n:::\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\n\nIf you prefer formal statistical test methods, the [`ols_test_normality()`](https://olsrr.rsquaredacademy.com/reference/ols_test_normality.html) of **olsrr** package can be used as shown in the code chun below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ols_test_normality(condo_fw_mlr$model)\n```\n:::\n\n\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.\n\n# 6. Testing for Spatial Autocorrelation\n\nThe hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.\n\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# mlr_output <- as.data.frame(condo_fw_mlr$model$residuals) %>%\n#   rename(`FW_MLR_RES` = `condo_fw_mlr$model$residuals`)\n```\n:::\n\n\nNext, we will join the newly created data frame with *condo_resale_sf* object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# condo_resale_sf <- cbind(condo_resale_sf, \n#                         mlr_output$FW_MLR_RES) %>%\n#   rename(`MLR_RES` = `mlr_output.FW_MLR_RES`)\n```\n:::\n\n\nNext, we will use **tmap** package to display the distribution of the residuals on an interactive map.\n\nThe code churn below will turn on the interactive mode of tmap.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# tmap_mode(\"view\")\n# tm_shape(mpsz)+\n#   tmap_options(check.and.fix = TRUE) +\n#   tm_polygons(alpha = 0.4) +\n# tm_shape(condo_resale_sf) +  \n#   tm_dots(col = \"MLR_RES\",\n#           alpha = 0.6,\n#           style=\"quantile\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# tmap_mode(\"plot\")\n```\n:::\n\n\nThe figure above reveal that there is sign of spatial autocorrelation.\n\n## 6.1 Spatial stationary test\n\nTo proof that our observation is indeed true, the Moran’s I test will be performed\n\nHo: The residuals are randomly distributed (also known as spatial stationary) H1: The residuals are spatially non-stationary\n\nFirst, we will compute the distance-based weight matrix by using [`dnearneigh()`](https://r-spatial.github.io/spdep/reference/dnearneigh.html) function of **spdep**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# condo_resale_sf <- condo_resale_sf %>%\n#   mutate(nb = st_knn(geometry, k=6,\n#                      longlat = FALSE),\n#          wt = st_weights(nb,\n#                          style = \"W\"),\n#          .before = 1)\n```\n:::\n\n\nNext, [`global_moran_perm()`](https://sfdep.josiahparry.com/reference/global_moran_perm) of sfdep is used to perform global Moran permutation test.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# global_moran_perm(condo_resale_sf$MLR_RES, \n#                   condo_resale_sf$nb, \n#                   condo_resale_sf$wt, \n#                   alternative = \"two.sided\", \n#                   nsim = 99)\n```\n:::\n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\n\nSince the Observed Global Moran I = 0.25586 which is greater than 0, we can infer than the residuals resemble cluster distribution.\n\n# 7. Building Hedonic Pricing Models using GWmodel\n\nIn this section, you are going to learn how to modelling hedonic pricing by using geographically weighted regression model. Two spatial weights will be used, they are: fixed and adaptive bandwidth schemes.\n\n## 7.1 Building Fixed Bandwidth GWR Model\n\n#### **Computing fixed bandwith**\n\nIn the code chunk below `bw.gwr()` of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Notice that the argument ***adaptive*** is set to **FALSE** indicates that we are interested to compute the fixed bandwidth.\n\nThere are two possible approaches can be uused to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using ***approach*** agreement.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# bw_fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n#                      PROX_CBD + PROX_CHILDCARE + \n#                      PROX_ELDERLYCARE   + PROX_URA_GROWTH_AREA + \n#                      PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n#                      PROX_SHOPPING_MALL + PROX_BUS_STOP + \n#                      NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n#                    data=condo_resale_sf, \n#                    approach=\"CV\", \n#                    kernel=\"gaussian\", \n#                    adaptive=FALSE, \n#                    longlat=FALSE)\n```\n:::\n\n\nThe result shows that the recommended bandwidth is 971.3405 metres. (Quiz: Do you know why it is in metre?)\n\n#### **GWModel method - fixed bandwith**\n\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# gwr_fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + \n#                          AGE    + PROX_CBD + PROX_CHILDCARE + \n#                          PROX_ELDERLYCARE   +PROX_URA_GROWTH_AREA + \n#                          PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH +\n#                          PROX_SHOPPING_MALL + PROX_BUS_STOP + \n#                          NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n#                        data=condo_resale_sf, \n#                        bw=bw_fixed, \n#                        kernel = 'gaussian', \n#                        longlat = FALSE)\n```\n:::\n\n\nThe output is saved in a list of class “gwrm”. The code below can be used to display the model output.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# gwr_fixed\n```\n:::\n\n\nThe report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the globel multiple linear regression model of 42967.1.\n\n## 7.2 Building Adaptive Bandwidth GWR Model\n\nIn this section, we will calibrate the gwr-based hedonic pricing model by using adaptive bandwidth approach.\n\n#### **Computing the adaptive bandwidth**\n\nSimilar to the earlier section, we will first use `bw.gwr()` to determine the recommended data point to use.\n\nThe code chunk used look very similar to the one used to compute the fixed bandwidth except the `adaptive` argument has changed to **TRUE**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# bw_adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n#                         PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n#                         PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n#                         PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n#                         NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n#                       data=condo_resale_sf, \n#                       approach=\"CV\", \n#                       kernel=\"gaussian\", \n#                       adaptive=TRUE, \n#                       longlat=FALSE)\n```\n:::\n\n\nThe result shows that the 30 is the recommended data points to be used.\n\n#### **Constructing the adaptive bandwidth gwr model**\n\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# gwr_adaptive <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n#                             PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n#                             PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n#                             PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n#                             NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n#                           data=condo_resale_sf, \n#                           bw=bw_adaptive, \n#                           kernel = 'gaussian', \n#                           adaptive=TRUE, \n#                           longlat = FALSE)\n```\n:::\n\n\nThe code below can be used to display the model output.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# gwr_adaptive\n```\n:::\n\n\nThe report shows that the AICc the adaptive distance gwr is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61.\n\n## 7.3 Visualising GWR Output\n\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:\n\n-   Condition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.\n\n-   Local R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\n\n-   Predicted: these are the estimated (or fitted) y values 3. computed by GWR.\n\n-   Residuals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produce by using these values.\n\n-   Coefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.\n\nThey are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called **SDF** of the output list.\n\n## 7.4 Converting SDF into *sf* data.frame\n\nTo visualise the fields in **SDF**, we need to first covert it into **sf** data.frame by using the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# gwr_adaptive_output <- as.data.frame(\n#   gwr_adaptive$SDF) %>%\n#   select(-c(2:15))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# gwr_sf_adaptive <- cbind(condo_resale_sf,\n#                          gwr_adaptive_output)\n```\n:::\n\n\nNext, `glimpse()` is used to display the content of *condo_resale_sf.adaptive* sf data frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# glimpse(gwr_sf_adaptive)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# summary(gwr_adaptive$SDF$yhat)\n```\n:::\n\n\n## 7.5 Visualising local R2\n\nThe code chunks below is used to create an interactive point symbol map.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# tmap_mode(\"view\")\n# tmap_options(check.and.fix = TRUE)\n# tm_shape(mpsz)+\n#   tm_polygons(alpha = 0.1) +\n# tm_shape(gwr_sf_adaptive) +  \n#   tm_dots(col = \"Local_R2\",\n#           border.col = \"gray60\",\n#           border.lwd = 1) +\n#   tm_view(set.zoom.limits = c(11,14))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# tmap_mode(\"plot\")\n```\n:::\n\n\n## 7.6 Visualising coefficient estimates\n\nThe code chunks below is used to create an interactive point symbol map.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# tmap_options(check.and.fix = TRUE)\n# tmap_mode(\"view\")\n# AREA_SQM_SE <- tm_shape(mpsz)+\n#   tm_polygons(alpha = 0.1) +\n# tm_shape(gwr_sf_adaptive) +  \n#   tm_dots(col = \"AREA_SQM_SE\",\n#           border.col = \"gray60\",\n#           border.lwd = 1) +\n#   tm_view(set.zoom.limits = c(11,14))\n# \n# AREA_SQM_TV <- tm_shape(mpsz)+\n#   tm_polygons(alpha = 0.1) +\n# tm_shape(gwr_sf_adaptive) +  \n#   tm_dots(col = \"AREA_SQM_TV\",\n#           border.col = \"gray60\",\n#           border.lwd = 1) +\n#   tm_view(set.zoom.limits = c(11,14))\n# \n# tmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n#              asp=1, ncol=2,\n#              sync = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# tmap_mode(\"plot\")\n```\n:::\n\n\n#### **By URA Plannign Region**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# tm_shape(mpsz[mpsz$REGION_N==\"CENTRAL REGION\", ])+\n#   tm_polygons()+\n# tm_shape(gwr_sf_adaptive) + \n#   tm_bubbles(col = \"Local_R2\",\n#            size = 0.15,\n#            border.col = \"gray60\",\n#            border.lwd = 1)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}